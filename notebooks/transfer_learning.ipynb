{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIXGeq5TMbvg",
        "outputId": "c744b118-845b-4e0d-e94c-d30ea9e519a5"
      },
      "source": [
        "!pip install wget\r\n",
        "import wget\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=f3a5db530234d5c859ebec7a07e761883218cdee9bd88fa08ae5296b79f42efc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av1RnZBMPfYn"
      },
      "source": [
        "if not os.path.isdir(\"data/PetImages\"):\r\n",
        "    wget.download(\"https://oshi.at/oShhsA\", bar=wget.bar_adaptive)\r\n",
        "\r\n",
        "    import zipfile\r\n",
        "    with zipfile.ZipFile(\"RfOr.zip\", \"r\") as zip_ref:\r\n",
        "        zip_ref.extractall(\"\")\r\n",
        "\r\n",
        "\r\n",
        "train_path = 'data/PetImages/train'\r\n",
        "valid_path = 'data/PetImages/valid'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aoL2ygUTUYD",
        "outputId": "c165866d-79bd-4ba9-a747-60feb28f2975"
      },
      "source": [
        "image_size = 224\r\n",
        "batch_size = 10\r\n",
        "\r\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\r\n",
        "    .flow_from_directory(directory=train_path,\r\n",
        "                         target_size=(image_size, image_size),\r\n",
        "                         classes=['Cat', 'Dog'],\r\n",
        "                         batch_size=batch_size)\r\n",
        "\r\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\r\n",
        "    .flow_from_directory(directory=valid_path,\r\n",
        "                         target_size=(image_size, image_size),\r\n",
        "                         classes=['Cat', 'Dog'],\r\n",
        "                         batch_size=batch_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fLDYXbtfMbvi"
      },
      "source": [
        "Wir verwenden nun das VGG16 Modell für Transfer Learning.\r\n",
        "Unser Ziel ist es, ein neuronales Netz zu erstellen, welches Bilder von Katzen und Hunden unterscheiden kann. Dies geht mit einfachen CNNs nicht so gut, deshalb versuchen wir es mit Transfer Learning bei einem bereits trainierten neuronalen Netz, welches wir auf unsere Bedürfnisse spezialisieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJiO8nIYMbvk",
        "outputId": "100f53fc-844b-4297-ed3f-d4b776947cd1"
      },
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
        "vgg16_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 16s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5qpC_sYMqE6"
      },
      "source": [
        "Wir erstellen nun ein eigenes Modell, das die gleichen Ebenen wie VGG16 hat außer der letzten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56dS1sOGNLoM"
      },
      "source": [
        "model = Sequential()\r\n",
        "for layer in vgg16_model.layers[:-1]:\r\n",
        "    model.add(layer)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5HwiG-GN0OL"
      },
      "source": [
        "Da wir die Ebenen vor unserer Spezialisierung (dem letzten voll vernetzen neuronalen Netz) nicht erneut trainieren wollen, werden wir diese freezen, d. h. `trainable = False` setzen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsGgTCN7Nj0V"
      },
      "source": [
        "Statt dem Dense Layer mit 1000 Outputs verwenden wir ein Dense Layer mit 2 Outputs - Katze oder Hund."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5qnw48OFBS"
      },
      "source": [
        "for layer in model.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Laxoy0tHNjbi",
        "outputId": "95b7cca9-f2ea-42bc-a106-26ce7357fe20"
      },
      "source": [
        "model.add(Dense(units=2, activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9J5HPEpOovd"
      },
      "source": [
        "Nun haben wir ein Modell, welches nur 8194 anpassbare Parameter hat statt 134 Millionen.\r\n",
        "Wir verwenden wieder `Adam` als Optimizer und categorical crossentropy loss als loss funktion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAtzv8dKO-AU"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwX__iQBUFWe",
        "outputId": "bd1b2c65-5051-4a0b-9522-5fbb29aa8d6c"
      },
      "source": [
        "model.fit(x=train_batches, validation_data=valid_batches, epochs=3, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 - 550s - loss: 0.2233 - accuracy: 0.9240 - val_loss: 0.1995 - val_accuracy: 0.9250\n",
            "Epoch 2/3\n",
            "100/100 - 543s - loss: 0.0835 - accuracy: 0.9690 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
            "Epoch 3/3\n",
            "100/100 - 544s - loss: 0.0513 - accuracy: 0.9850 - val_loss: 0.1777 - val_accuracy: 0.9450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8829512f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}