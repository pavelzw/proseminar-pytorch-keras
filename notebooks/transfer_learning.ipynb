{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIXGeq5TMbvg",
        "outputId": "5e77de6e-3a3b-4cf5-b69c-7ca314292810"
      },
      "source": [
        "!pip install wget\r\n",
        "import wget\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av1RnZBMPfYn"
      },
      "source": [
        "if not os.path.isdir(\"data/PetImages\"):\r\n",
        "    wget.download(\"https://oshi.at/twJYYz\", bar=wget.bar_adaptive)\r\n",
        "\r\n",
        "    import zipfile\r\n",
        "    with zipfile.ZipFile(\"JuIO.zip\", \"r\") as zip_ref:\r\n",
        "        zip_ref.extractall(\"\")\r\n",
        "\r\n",
        "\r\n",
        "train_path = 'data/PetImages/train'\r\n",
        "valid_path = 'data/PetImages/valid'\r\n",
        "test_path = 'data/PetImages/test'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aoL2ygUTUYD",
        "outputId": "25d7ed49-e207-431f-b883-78cf1c8712d2"
      },
      "source": [
        "image_size = 224\r\n",
        "batch_size = 10\r\n",
        "\r\n",
        "classes = ['Cat', 'Dog']\r\n",
        "\r\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\r\n",
        "    .flow_from_directory(directory=train_path,\r\n",
        "                         target_size=(image_size, image_size),\r\n",
        "                         classes=classes,\r\n",
        "                         batch_size=batch_size)\r\n",
        "\r\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\r\n",
        "    .flow_from_directory(directory=valid_path,\r\n",
        "                         target_size=(image_size, image_size),\r\n",
        "                         classes=classes,\r\n",
        "                         batch_size=batch_size)\r\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\r\n",
        "    .flow_from_directory(directory=test_path,\r\n",
        "                         target_size=(image_size, image_size),\r\n",
        "                         classes=classes,\r\n",
        "                         batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fLDYXbtfMbvi"
      },
      "source": [
        "Wir verwenden nun das VGG16 Modell für Transfer Learning.\r\n",
        "Unser Ziel ist es, ein neuronales Netz zu erstellen, welches Bilder von Katzen und Hunden unterscheiden kann. Dies geht mit einfachen CNNs nicht so gut, deshalb versuchen wir es mit Transfer Learning bei einem bereits trainierten neuronalen Netz, welches wir auf unsere Bedürfnisse spezialisieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJiO8nIYMbvk",
        "outputId": "ccc18b9f-6eee-43df-a833-d00c7f12bc82"
      },
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
        "vgg16_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5qpC_sYMqE6"
      },
      "source": [
        "Wir erstellen nun ein eigenes Modell, das die gleichen Ebenen wie VGG16 hat außer der letzten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56dS1sOGNLoM"
      },
      "source": [
        "model = Sequential()\r\n",
        "for layer in vgg16_model.layers[:-1]:\r\n",
        "    model.add(layer)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5HwiG-GN0OL"
      },
      "source": [
        "Da wir die Ebenen vor unserer Spezialisierung (dem letzten voll vernetzen neuronalen Netz) nicht erneut trainieren wollen, werden wir diese freezen, d. h. `trainable = False` setzen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsGgTCN7Nj0V"
      },
      "source": [
        "Statt dem Dense Layer mit 1000 Outputs verwenden wir ein Dense Layer mit 2 Outputs - Katze oder Hund."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5qnw48OFBS"
      },
      "source": [
        "for layer in model.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Laxoy0tHNjbi",
        "outputId": "d57572a3-6f8e-47d1-b7c8-acb59350cc30"
      },
      "source": [
        "model.add(Dense(units=2, activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9J5HPEpOovd"
      },
      "source": [
        "Nun haben wir ein Modell, welches nur 8194 anpassbare Parameter hat statt 134 Millionen.\r\n",
        "Wir verwenden wieder `Adam` als Optimizer und categorical crossentropy loss als loss funktion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAtzv8dKO-AU"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwX__iQBUFWe",
        "outputId": "50a392c3-2b59-4e91-a5ff-b96ee4c802be"
      },
      "source": [
        "model.fit(x=train_batches, validation_data=valid_batches, epochs=3, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 - 613s - loss: 0.5406 - accuracy: 0.7890 - val_loss: 0.2336 - val_accuracy: 0.9100\n",
            "Epoch 2/3\n",
            "100/100 - 608s - loss: 0.1212 - accuracy: 0.9590 - val_loss: 0.1715 - val_accuracy: 0.9400\n",
            "Epoch 3/3\n",
            "100/100 - 608s - loss: 0.0685 - accuracy: 0.9830 - val_loss: 0.1550 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1696e1208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtmIUk3Ryej8"
      },
      "source": [
        "Nun betrachten wir wieder das Test-Set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Wfcg1xy27E"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "import itertools\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def plot_cm(y_true, y_pred, classes, title='Konfusionsmatrix', cmap=plt.cm.Blues):\r\n",
        "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    thresh = cm.max() * 2. / 3\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, cm[i, j],\r\n",
        "            horizontalalignment=\"center\",\r\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('Tatsächlich')\r\n",
        "    plt.xlabel('Vorhersage')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rman8Yre9JMo",
        "outputId": "e163807c-db66-407a-ad9b-92a7152ad14d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = model.predict(x=test_batches, verbose=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 - 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktflor_V9JsA",
        "outputId": "4d0ed38b-2b84-44c1-da96-d1ba2bce471a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\r\n",
        "preds = np.argmax(predictions, axis=1)\r\n",
        "print(\"Predictions:\\n\", preds)\r\n",
        "print(\"Actual:\\n\", test_batches.classes)\r\n",
        "print(\"Accuracy:\", sum(preds == test_batches.classes)/preds.shape[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions:\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Actual:\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Accuracy: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "4yo9-6e1y3ml",
        "outputId": "13aea7e6-5d53-4e4e-bfa5-9620d33e411b"
      },
      "source": [
        "plot_cm(test_batches.classes, preds, classes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEmCAYAAAAA6gkZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdyklEQVR4nO3debxd87nH8c/3nCQSIiJiJqYIDW3TJqaWqqFXlBpadSkSldJJtTWUUqq9bWndW/MUShMz1Uh44WoRErMQBG2Da2iFJI2QIGR47h9rHXZiT+fYZ+/fzvm++1qvs+b1nKR5/Kb1W4oIzMzso1oaHYCZWaqcIM3MSnCCNDMrwQnSzKwEJ0gzsxKcIM3MSnCCNCRtJmmqpHmSjvoY97lI0sm1jC0FkuZL2rjRcVj9yeMgm4ukF4FvRcRf8+0DgAuBfSLing7e8w/AWxHx45oF2gQkTQSujIhLGx2LpcklyCYmaSRwPrBHR5NjbgPg6dpEtfyQ1K3RMVhjOUE2KUnfBv4H2C0i7pe0jqQJkuZIek7S4QXnnirpeklj82r005KG5cfuAnYCzsurkoMkTZT0rYLrD5U0OV+XpDMlzZT0lqSnJG2ZH/ujpF8VXHd4HsucPLZ1Co6FpO9Imi5prqTzJSk/NlDSPZLelDRb0nXLXPe9/Lp5kv5L0iaS7s/juV5Sj/zcVSXdImmWpDfy9fXyY78Gdij4vc8ruP/3JU0HphfsGyipR94U8YN8f6uk+ySdUsO/WktJRHhpogV4EbgReB34dMH+e4ELgJ7AEGAWsHN+7FRgAfBloBU4DXiw4NqJZNX2UtuHApPz9d2AKUBfQMAngLXzY38EfpWv7wzMBj4LrACcC9xbcM8AbsnvMyCPd3h+7BrgJLL/gPcEtl/muvFAH2AL4D3gTmBjYBXgGWBkfu5qwNeAFYGVgRuAm0r9ngX3/wvQD+hVsG9gvr4l8Eb+e58EPAi0Nvr/F146Z3EJsjl9iewf5lMAktYHPg8cHxELImIqcCkwouCayRFxa0QsBq4APt3BZy8kSzabk7VhPxsRM4qcdxBwWUQ8FhHvAT8FtpO0YcE5p0fE3Ih4GbibLLG3PWMDYJ3895m8zL1/FxFvRcTTwDTgjoh4ISLeBG4DPgMQEf+OiBsj4p2ImAf8Gtixit/xtIiYExHvLnsgIqYBvwJuAo4FDsn/TG055ATZnL4LDAIuzaul6wBz8iTQ5iVg3YLt1wrW3wF6dqSNLSLuAs4ja/ucKWm0pD5FTl0nj6HtuvnAvyvE1Dtf/wlZ6fThvDngsGXu/XrB+rtFtnsDSFpR0sWSXpL0Flkpu6+k1gq/5isVjo8hS+C3RsT0CudaE3OCbE6vA7uQtaFdALwK9JO0csE5A4B/dfD+b5NVS9usVXgwIs6JiKHAYLJEfVyRe7xKlkQAkLQSWZW3YkwR8VpEHB4R6wDfBi6QNLDdvwUcA2wGbBMRfYAvtIXT9qhSIVS47wVkzQO7Sdq+A3FZk3CCbFIR8SpZkhwOHA3cD5wmqaekTwGjgCs7ePupwFfzEtjA/F4ASNpK0jaSupMl0gXAkiL3uAb4pqQhklYAfgM8FBEvVnq4pK+3daaQtfdFiWdUsjJZiXKupH7Az5c5/jpZ22XVJB0CDCVrlz0KGCOpd9mLrGk5QTaxvO1uZ2A/4DlgQ7KS2zjg55GPleyAM4H3yRLIGOCqgmN9gEvIEtdLZNXmM4rE9lfgZLIOpRnAJsABVT5/K+AhSfOBCcAPI+KFDvweZwG9yDqLHgRuX+b42cB+eQ/3OZVuJmlAfs8RETE/Iq4GHiX787LlkAeKm5mV4BKkmVkJTpBmZiU4QZqZleAEaWZWQtO/jK8eK4V69mt0GNYBn9xkjUaHYB30yssvMeffs1X5zOq19tkgYtFHXl4qKt6d9b8RMbyWzy+m+RNkz36ssO0PGx2GdcDtN3R46klrsOFf3K7m94xF77LCZvtXde6Cqef3r3kARTR9gjSz5YVAabX6OUGaWRoEqKa19o/NCdLM0tFSaR6R+nKCNLNEuIptZlaaq9hmZkUIlyDNzIqTS5BmZiW5BGlmVozci21mVpTHQZqZleEqtplZMR4HaWZWWour2GZmH+VxkGZmZbiTxsysGA/zMTMrzVVsM7Mi5FcNzcxKcwnSzKwElyDNzIrxQHEzs+KEe7HNzIpzCdLMrDS3QZqZleASpJlZCS5BmpkVIbdBmpmV5hKkmdlHCWhpcQnSzOyjlC8JcYI0s0QIuYptZlacE6SZWQlOkGZmJThBmpkVIQn5q4ZmZsW5BGlmVkJqCTKtUZlm1qVJqmqp8l6tkh6XdEu+vZGkhyQ9J+k6ST0q3cMJ0szSoHYs1fkh8GzB9m+BMyNiIPAGMKrSDZwgzSwZtSpBSloP2AO4NN8WsDPwp/yUMcA+le7jNkgzS4La9yZNf0mPFmyPjojRBdtnAT8BVs63VwPmRsSifPufwLqVHuIEaWbJaMcwn9kRMazoPaQ9gZkRMUXSFz9OPE6QZpYG1awX+/PAXpK+DPQE+gBnA30ldctLkesB/6p0I7dBmlkyatEGGRE/jYj1ImJD4ADgrog4CLgb2C8/bSQwvlI8TpBmloxaDvMp4njgaEnPkbVJ/qHSBa5im1kS2tlJU5WImAhMzNdfALZuz/VOkGaWjrRepHGCTE1Li7jvvIN5dfZ8vnbKOEYfO5wdPrU+b779HgBHnHEbT74wq8FRWiVbf3IQvVfuTUtLK926deP2iQ80OqT0yZ9csAqO3Pez/P3lOay84odvQZ14yT2Mm/SPBkZlHXHDzXew2mr9Gx1GU/G72FbSuv17M3zrjbn89icbHYpZY9T2VcOPzQkyIWd8d2dOuvRelixZev+ph27PwxeN5Hff+SI9urc2JjhrFwkO3HcPdttxW67846WNDqdpdHIvdrvVLUFKWkvStZKelzRF0q2SBpU4t6+k79UrthTsvs3GzJz7Do9Pf32p/adcNolPj7qM7X9wJauu3Itj9m9XJ5w1yE23380d9z7EVX+awB8vuYgH75vU6JCSV21yXO4SZP6i+DhgYkRsEhFDgZ8Ca5a4pC/QpRLkdlusy57bbsLfxh7O2BP35ItDBnDZ8V/mtTlvA/D+wsWM/d9pDNtsrQZHatVYe53sNd/+q6/B8D335vHHHmlwRM2hSyZIYCdgYURc1LYjIp4AHpd0p6THJD0lae/88OnAJpKmSjqjTjE21CmXTWLgQRez+YhLGPGbW5g49WUO++2trNVvpQ/O2etzA3nmxdkNjNKq8c7bbzN/3rwP1u+5+69s/oktGhxVc0gtQdarF3tLYEqR/QuAfSPiLUn9gQclTQBOALaMiCHFbibpCOAIAHr27ZyIE3H5CXvQf5VeSOLJ52fyg7P/0uiQrIJZs15n1EH7A7Bo8SL23e8Adtp1twZH1Rz8TZqlCfiNpC8AS8imHypV7f5APq3RaICWPutHp0bYAJOefIVJT74CwO4/ub7B0Vh7bbDhxvz1vkcrn2hLq91kFTVTrwT5NB++JF7oIGB1YGhELJT0ItnsG2bWxYis9z8l9WqDvAtYIa8aAyDpU8AGZPO2LZS0U74NMI8PJ7o0sy6hi/ZiR0QA+wK75sN8ngZOA24Fhkl6ChgB/C0//9/AfZKmdZVOGjPLSpDVLPVStzbIiHgV2L/Ioe1KnP+Nzo3IzFLTVdsgzczKkqC11QnSzKyoxAqQTpBmlg5Xsc3MiqlzB0w1nCDNLAnZOMi0MqQTpJklor5jHKvhBGlmyUgsPzpBmlkilH2TKSVOkGaWBLdBmpmVkVh+dII0s3S4BGlmVkJi+dEJ0swS0YUnzDUzKyvFCXOdIM0sEfIwHzOzUlzFNjMrxpNVmJkV54HiZmZlOEGamZWQWH50gjSzRHiyCjOz4uT5IM3MSkssP9LS6ADMzNq0SFUtlUjqKelhSU9IelrSL/L9G0l6SNJzkq6T1KPcfaoqQUr6HLBh4fkRMbaaa83MqlXDEuR7wM4RMV9Sd2CypNuAo4EzI+JaSRcBo4ALS92kYoKUdAWwCTAVWJzvDsAJ0sxqRjWcrCIiApifb3bPlwB2Br6R7x8DnMrHSZDAMGBw/kAzs07Tjk7s/pIeLdgeHRGjC0+Q1ApMAQYC5wPPA3MjYlF+yj+Bdcs9pJoEOQ1YC5hRZeBmZh3SjmE+syNiWLkTImIxMERSX2AcsHl74ymZICXdTFYkXRl4RtLDZPX6tofv1d6HmZmVIrKhPrUWEXMl3Q1sB/SV1C0vRa4H/KvcteVKkP9dwxjNzCqq1ThxSasDC/Pk2Av4EvBb4G5gP+BaYCQwvtx9SibIiLgnf9BGwIyIWJBv9wLWrMUvYWb2AdV0oPjawJi8HbIFuD4ibpH0DHCtpF8BjwN/KHeTatogbwA+V7C9ON+3VYfCNjMroVb5MSKeBD5TZP8LwNbV3qeaBNktIt4veMD7lQZXmpm1l6CqQeD1VM2bNLMkfdAhI2lvYHbnhWRmXVVLi6pa6qWaEuR3gKsknUeW5F8BRnRqVGbW5agZZxSPiOeBbSX1zrfnV7jEzKxDUqtilxsHeXBEXCnp6GX2AxARv+/k2Mysi0krPZYvQa6U/1y5HoGYmTXNfJARcXH+8xf1C8fMuqqsF7vRUSytXBX7nHIXRsRRtQ/HzLqs2g4Ur4lyVewpdYvCzIwm+iZNRIypZyBm1rU1VRW7jaRBwLF8dEbxnTsvLDPripqpit3mBuAi4FI+nFHczKzm0kqP1SXIRRFRckpyM7NakJproHi/fPVmSd8jm5G3cMLcOZ0cm5l1MYnlx4q92MGHpd7jCo4FsHFnBWVmXVMz9WJvVM9AzKxrE9V987qequnF/j5wVUTMzbdXBQ6MiAs6O7hqfGbTNbnv1mMbHYZ1wKpbHdnoEKyD3vv7K7W/aYKz+VQzH+ThbckRICLeAA7vvJDMrKtS/jZNpaVequnFbpWktu9i59948IziZlZz1ZTY6qmaBHk7cJ2ki/Ptb+f7zMxqRjTnQPHjyZLid/Ptv5ANGjczq6nEOrGrmlF8CXBhvpiZdQoJWhPLkNX0Ym8KnAYMBnq27Y8Ij4M0s5pKLD+WbhOVNDlfvZys9LgI2AkYC1zZ+aGZWVfT9uGuSku9lOs0+nL+s1dE3AkoIl6KiFOBPTo9MjPrUtq+i13NUi/lEuTV+c/3JLUA0yUdKWlfoHfnh2ZmXU1LlUs94ykqIvbMV39M9gGvo4ChwCHAyM4Pzcy6mtSq2NX0Yj+Ur86TNAroHRFvdW5YZtbVSEquF7tiaVXS1ZL6SFoJmAY8I+m4SteZmbVXi6pb6hZPFecMzkuM+wC3ARuRVbPNzGqm2Tpp2nSX1J0sQU6IiIWdHJOZdVGptUFWkyAvBl4k66i5V9IGwJudGZSZdUFVVq/rWcWu5l3smyPinLYNSS8Dh3VeSGbWVSmxz3ZVU4K8sXAjn/bs2s4Jx8y6qrbvYjdFCVLS5sAWwCqSvlpwqA8F72SbmdVKasN8ylWxNwP2BPoCXynYPw/PKG5mNdZWgkxJuY92jQfGS9ouIh6oY0xm1hUl+E2aajppHs8/3LUFS0935o4aM6upWo1xlLQ+2cxja5J9pnp0RJwtqR9wHbAh2eic/fPvbBWPp4pnXQGsBewG3AOsR1bNNjOrmRp30iwCjomIwcC2wPclDQZOAO6MiE2BO/PtksrNB9lWuhwYEScDb0fEGLKpzrapKkQzs3ao1UDxiJgREY/l6/OAZ4F1gb2BMflpY8hegCmpXAny4fxn25szcyVtCawCrFE5RDOz9hAtVS7tuqu0IfAZ4CFgzYiYkR96jawKXlI1bZCjJa0K/AyYQDYX5MntitDMrILsmzRVn95f0qMF26MjYvRH76neZGO5fxQRbxV+NTEiQlKUe0i5BLmGpKPz9W/mP8/Pf65UKXozs/ZqRyfN7IgYVu6EfA6JG4GrIuLP+e7XJa0dETMkrQ3MLBtPmWOtZKXFlQuW3gWLmVnNZN/Frk0bpLKi4h+AZyPi9wWHJvDhhN8jgfHl7lOuBDkjIn5ZORQzs9qo4VRmnyeblvEpSVPzfScCpwPX55N/vwTsX+4m5RJkYkM2zWx5V6v8GBGTKZ3Ddqn2PuUSZNU3MTP7uER9P8hVjXKvGs6pZyBm1sWpplXsmqhmmI+ZWadr++RCSpwgzSwZaaVHJ0gzS0hiBUgnSDNLhVBiGdIJ0syS0FS92GZm9eYSpJlZMR7mY2ZWnKvYZmZluIptZlZCWunRCdLMEpJYAdIJ0szSkLVBppUhnSDNLBFyL7aZWSmJ5UcnSDNLg6vYZmalVPm9mXpygjSzZDhBmpmVoMSq2Km92WO5b3/rMAasswZDh2zZ6FCsSi0t4oFrjufGs78DwI5bDeL+q4/n0RtO5JJfHkJrq/+5lZPNKF7dUi/+G0vUISMPZfwttzc6DGuHI7+xE3//v9eB7JW5S395CCNOuJxhX/8NL8+Yw8Ff2abBEaavRapqqVs8dXuStcv2O3yBfv36NToMq9K6a/Rl+PZbcPm4+wFYre9KvL9wEc+9PBOAux78G/vsMqSRITYFVfm/enGCNKuBM477GiedfRNLlgQAs9+YT7durXx28AAA9t11COutuWojQ0xel6piS1osaaqkpyU9IekYSU7IttzZfYctmTlnHo8/+8pS+0eccDm/O+arTLriWOa9/R6LlyxpUITNotryY/0yZGf2Yr8bEUMAJK0BXA30AX7eic80q7vthmzMnjt+kuHbb8EKPbrTZ6WeXParERz2s7HsOuosAHbZdnM23WCNBkeauATHQdalRBcRM4EjgCOV6SnpcklPSXpc0k4AklaUdL2kZySNk/SQpGH1iNGso045dwIDh5/M5nv8nBEnXM7ER/7BYT8by+qr9gagR/duHHPol7jkT5MbHGn6VOVSL3UbBxkRL0hqBdYADs52xSclbQ7cIWkQ8D3gjYgYLGlLYGqxe0k6gizhsv6AAfX5BepsxMEHMumeicyePZtNNlyPk0/5BYceNqrRYVk7/Hjkruy+w5a0tIhLbpjEPY/8o9EhJU1Aa2JFyEYNFN8eOBcgIv4m6SVgUL7/7Hz/NElPFrs4IkYDowGGDh0WdYm4zsZeeU2jQ7AOmDRlOpOmTAfgxLNu4sSzbmpwRE0mrfxYvwQpaWNgMTCzXs80s+bSJd+kkbQ6cBFwXkQEMAk4KD82CBgA/B24D9g/3z8Y+GQ94jOzNEjVLfXSmSXIXpKmAt2BRcAVwO/zYxcAF0p6Kj92aES8J+kCYIykZ4C/AU8Db3ZijGaWkLTKj52YICOitcyxBcA3ixxaABwcEQskbQL8FXipk0I0s9QkliFTm81nReBuSd3J/qi+FxHvNzgmM6uDbAhPWhkyqQQZEfMAj3s064rq/BphNZJKkGbWxTlBmpkVU9/3rKvhBGlmyUjsRRpPd2Zmaaj2PexqcqikyyTNlDStYF8/SX+RND3/WXH+OSdIM0tH7War+CMwfJl9JwB3RsSmwJ35dllOkGaWjFp9ciEi7gXmLLN7b2BMvj4G2KfSfdwGaWbJaEcTZH9JjxZsj84nsSlnzYiYka+/BqxZ6SFOkGaWhvZN9jg7Ijo8ZjoiQlLFmcBcxTazZHTyJxdel7Q2QP6z4sxiTpBmlgTR6bP5TABG5usjgfGVLnCCNLNk1HCYzzXAA8Bmkv4paRRwOvAlSdOBXfPtstwGaWbpqNFA8Yg4sMShXdpzHydIM0tGNUN46skJ0sySkVZ6dII0s5QkliGdIM0sCZ4w18yslDp/kKsaTpBmlozE8qMTpJmlQiixIqQTpJklI7H86ARpZmlo31wV9eEEaWbpSCxDOkGaWTI8zMfMrAS3QZqZlZBYfnSCNLNECA/zMTMrpm3C3JQ4QZpZMhLLj06QZpYOlyDNzErwMB8zs1LSyo9OkGaWjsTyoxOkmaVB8jdpzMxKSys/OkGaWToSy49OkGaWjsRq2E6QZpYKeZiPmVkxftXQzKwMJ0gzsxJcxTYzK8bfxTYzK84f7TIzKyexDOkEaWbJcBukmVkJboM0MyvBCdLMrITUqtiKiEbH8LFImgW81Og4OlF/YHajg7AOWZ7/7jaIiNVreUNJt5P9mVVjdkQMr+Xzi2n6BLm8k/RoRAxrdBzWfv67a34tjQ7AzCxVTpBmZiU4QaZvdKMDsA7z312TcxukmVkJLkGamZXgBGlmVoITpJlZCU6QZmYlOEEmTlKvgvXejYzFrKtxL3bC8uR4GPAYsDYwGDg9IhY1NDCrmiRFREhaFXg7It5vdExWPU9WkbCIeFfSY8AtwFxg84hY1PaPrsHhWQUFyXEb4JfAecDNDQ7L2sFV7ARJS036NAt4Bngf2KHCuZaQPDnuDpxIVhg5X9JuklobHJpVyQkyMYWlQ0krRcRzEbEDcBRwlqSv5f/wtpO0hkuS6ZK0DvBfZM0iuwCnAT8DOn0WGqsNJ8jEFCTHY4HLJd0raeuI+AtwCvDfki4CzsBNJKmbCfyD/N9ZRFwI3AdcLGlrcA0gdU6QiZA0VNLWknpK+jawO3AgEMANkv4jIm4CDgLeAb4VEa82MGRbRluyk7SKpNXyzrTXgG3y0iTAOOCfwKWS+roGkDaXQBIgaThZVexc4N9kfy+HAj8CXgeuA66VNDIibpb0YEQsaVS8Vlze9LEXcBzQIukOYDzZ3+NASQuBnYGvA0cDa5J1vlmiPMynwSTtCFwKfCMiHsn3CRgAXA7sFRHzJd1PVnL8SkS827CA7SMKeqsHA2OAI8iq1+cADwBXA58FPgHcSjZr9kXAzhExozFRWzVcgmy8ocB5EfGIpG4RsSj/xzaLrCr21bzX81ngl06O6ZDUkpfkRdYU0oPs7+zvEfGOpG8Bk4GZETEWuEXStmT/QdzXyTF9TpANUtBbvRHwZr57ccEpi4AnyIb2bAf8Z0Qsz9/eaSqSBgEjJPUhq06fAbwMvAt8WtKTEfGGpPOXufRRspLjK3UO2TrAnTQNUtA4Pw7YVtLQvOTYIqk1f+NiIXA+8IWIeLphwdpSJG0G/Jmsvfh5stLjA8C6wF3AMcB3JY0ga2t8Jb9OeQ3BybFJuATZeA+RVcP+UxIRMQVA0oHASGBcRMxpZID2obyd8SrgxIiYULB/JtlbMkPJvrK5NbAT8N2IuBuW+o+iNQl30iRA0rrAKGAXsirYu8B+wH4RMa2RsdnSJG0P3BsRLfl2r7Z2YUlnAatGxMh8u5vfm29urmInICL+RTbw+yRgHlmVbC8nx/RExGRgD0nP52Md35XUMz/8AEvXyhZ/9A7WTFzFTkReCpmcL5awiLhN0pHAw5K2KmgCeQ+YK6k7sMhV6ubnEqRZB0TEbcCRZE0ibR03pwM3R8RCJ8flg9sgzT6GfLaeG4H/A46LiFsbHJLVkBOk2cckaRegT0SMa3QsVltOkGY14omMlz9OkGZmJbiTxsysBCdIM7MSnCDNzEpwgrQPSLpb0m7L7PuRpAurvH5+50Rm1hhOkFboGuCAZfYdkO8v6+N+qU+S3+qy5DhBWqE/kb1n3ANA0obAOsC6kp6SNE3Sb9tOljRf0v9IeoJszkok/VrSE5IelLRmvm91STdKeiRfPp/vP1XSFZLuA66QtIWkhyVNlfSkpE3z826SNEXS05KOKHj+KEn/yK+5RNJ55Z5n1m4R4cXLBwtwC7B3vn4CcBnZRLCrk727fxewT348gP0Lrg2yT0IA/A74Wb5+NbB9vj4AeDZfPxWYAvTKt88FDsrXexTs75f/7AVMA1YjS9wvAv2A7sAkspnZSz7Pi5f2Lq7W2LLaqtnj85/jgIkRMQtA0lXAF4CbyGarubHg2vfJEixkie9L+fquwOCCL5z2kdQ7X58QH35G4gHgJEnrAX+OiOn5/qMk7Zuvrw9sCqwF3BP5RBGSbgAGlXteRLiN1NrFCdKWNR44U9JngRWBqcAmJc5dEBGFU3oVTtKwmA///9UCbBsRCwovzhPY223bEXG1pIeAPYBb88/fLiFLeNtF9p2XiUBPyiv6PLP2chukLSUvZd1NVrW+BngY2FFS/7wj5kDgnnbe9g7gB20bkoYUO0nSxsALEXEOWaL+FLAK8EaeHDcHts1PfySPa9W8g+dr7X2eWSVOkFbMNcCngWsi+/LeCWRJ8wlgSkSMb+f9jgKG5R0vzwDfKXHe/sA0SVOBLYGxwO1AN0nPkk0n9iB8MMnwb8gS+H1k7ZFtHz+r9nlmZfldbGtabe2KeQlyHHBZeEYdqyGXIK2ZnZqXNqeRzcd4U4PjseWMS5BmZiW4BGlmVoITpJlZCU6QZmYlOEGamZXgBGlmVsL/A22qPYU9xSSZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}