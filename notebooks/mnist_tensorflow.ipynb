{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Beispiel sehen wir uns MNIST an.\n",
    "Hierbei handelt es sich um eine Datenbank aus\n",
    "70000 handgeschriebenen Ziffern, davon 60000 im Trainings-\n",
    "und 10000 im Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Betrachten beispielhaft wir die erste Ziffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Value: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fst_image = x_train[0]\n",
    "fst_digit = y_train[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(fst_image)\n",
    "plt.title(f\"Value: {fst_digit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multilayer Perceptron\n",
    "Nun erstellen wir die Architektur des neuronalen Netzes. Wir verwenden hier ein Fully Connected Neural Network mit einem Hidden Layer mit 64 Knoten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<img src=\"assets/fcnn-28x28-64-10.svg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "class MultiLayerPerceptron(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flat = Flatten(input_shape=(28,28))\n",
    "        self.fc1 = Dense(64, activation='relu')\n",
    "        self.fc2 = Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_rate = 0.01\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_layer_perceptron\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MultiLayerPerceptron()\n",
    "model.build((batch_size, 28, 28))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1200/1200 - 4s - loss: 0.8074 - accuracy: 0.8000 - val_loss: 0.4168 - val_accuracy: 0.8881\n",
      "Epoch 2/3\n",
      "1200/1200 - 2s - loss: 0.3880 - accuracy: 0.8936 - val_loss: 0.3318 - val_accuracy: 0.9084\n",
      "Epoch 3/3\n",
      "1200/1200 - 2s - loss: 0.3299 - accuracy: 0.9070 - val_loss: 0.2959 - val_accuracy: 0.9172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15fde572520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs=3, validation_data=(x_test, y_test), batch_size=batch_size, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
