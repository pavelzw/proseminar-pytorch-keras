{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Einführung in PyTorch, TensorFlow und Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyTorch\n",
    "- 2017 von Facebook veröffentlicht\n",
    "- Basierend auf Torch (Bibliothek für Lua, 2002)\n",
    "- Bereits von Anfang an sehr Pythonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensorFlow\n",
    "- 2015 von Google veröffentlicht\n",
    "- TensorFlow 1 schwieriger zu lernen als PyTorch\n",
    "- TensorFlow 2 (Sep. 2019) deutlich mehr Pythonic\n",
    "- Keras früher eigenständig, seit 1.4 Teil der Core API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:#4285f4\">PyTorch</span> vs. <span style=\"color:#db4437\">TensorFlow</span> Google Suchtrends (Weltweit)\n",
    "<img src=\"search-trends.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verteiltes Rechnen\n",
    "Google hat Tensor Processing Units (TPUs) entwickelt, welche deutlich schneller als normale GPUs Modelle trainieren können. \n",
    "\n",
    "| | PyTorch | TensorFlow |\n",
    "| ---: | :---: | :---: |\n",
    "| CPU/GPU | ✅ | ✅ |\n",
    "| TPU | Drittanbieter Bibliotheken | ✅ |\n",
    "| Kubernetes | ✅ | ✅ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deployment\n",
    "- TensorFlow unterstützt statische Berechnungsgraphen → bessere Performance\n",
    "- TensorFlow hat bessere Packages, die Deployment über Cloud, Browser und Mobile vereinfachen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code\n",
    "- Beide sehr Pythonic, unterscheiden sich mittlerweile kaum noch\n",
    "- Keras API vereinfacht einiges in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Modellerstellung PyTorch\n",
    "```py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TorchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Linear(21632, 128)\n",
    "        self.d2 = Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = self.d2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Modellerstellung TensorFlow\n",
    "```py\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "class TFModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.conv1 = Conv2D(filters=32, kernel_size=3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        output = self.d2(x)\n",
    "        return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AMD und Apple Silicon\n",
    "\n",
    "| | PyTorch | TensorFlow |\n",
    "| ---: | :---: | :---: |\n",
    "| OpenCL (AMD) | ❌ | ❌ |\n",
    "| Apple Silicon | ❌ | ✅ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"apple-silicon.png\" style=\"width:570px;height:500px;\"/></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
