{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "mask_nn.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "EEmVUQOSzKg2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "daea105f-c744-4598-b0d2-d895d3d32707"
   },
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\pavel\\miniconda3\\envs\\pytorch\\lib\\site-packages (3.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun betrachten wir einen Datensatz mit korrekt/inkorrekt getragenen Gesichtsmasken.\n",
    "\n",
    "Es gibt diese Möglichkeiten zur Nutzung der Maske:\n",
    "- Korrekte Nutzung\n",
    "- Kinn\n",
    "- Mund/Nase\n",
    "- Mund/Kinn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "classes = ['correct', 'chin', 'mouth_nose', 'mouth_chin']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zuerst laden wir den präparierten Datensatz herunter und entpacken diesen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p2Je_Jpx1qPy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "588c6f5a-a7f4-4041-a35e-5baa0a1bd8c8"
   },
   "source": [
    "if not os.path.isdir(\"data/MaskFace-Net\"):\n",
    "    wget.download(\"https://oshi.at/NVKYum\", bar=wget.bar_adaptive)\n",
    "\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(\"jOLG.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"\")"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4qkVaiWizKg-"
   },
   "source": [
    "train_path = 'data/MaskFace-Net/train'\n",
    "valid_path = 'data/MaskFace-Net/valid'\n",
    "test_path = 'data/MaskFace-Net/test'"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "eMY22wgozKhA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f10344f4-06bc-4db9-cca1-9add9e53ade8"
   },
   "source": [
    "Nun erzeugen wir aus den Ordnern die zugehörigen Batches.\n",
    "`tf.keras.applications.vgg16.preprocess_input` passt hierbei den Input\n",
    "noch für das neuronale Netz an.\n",
    "`flow_from_directory` erzeugt augmentierte Bilder.\n",
    "In unserem Beispiel werden diese einfach auf die Größe `256x256` skaliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "batch_size = 10\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path,\n",
    "                         target_size=(image_size, image_size),\n",
    "                         classes=classes,\n",
    "                         batch_size=batch_size)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path,\n",
    "                         target_size=(image_size, image_size),\n",
    "                         classes=classes,\n",
    "                         batch_size=batch_size)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path,\n",
    "                         target_size=(image_size, image_size),\n",
    "                         classes=classes,\n",
    "                         batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "JdJ6LksfzKhC"
   },
   "source": [
    "assert train_batches.n == 4*300\n",
    "assert valid_batches.n == 4*100\n",
    "assert test_batches.n == 4*50\n",
    "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 4"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rceDQDtPzKhE"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "1B1auTcezKhE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "outputId": "50a10e13-21f7-456c-f394-367f014713a3"
   },
   "source": [
    "Sehen wir uns das erste Trainingsbatch kurz an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "\n",
    "plot_images(imgs)\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun kommen wir endlich zu unserem neuronalen Netz.\n",
    "Wir verwenden ein Convolutional Neural Network, das durch `tf.keras.models.Sequential`\n",
    "realisiert und verwendet zwei `tf.keras.layers.Conv2D`-Ebenen, zwei `tf.keras.layers.MaxPool2D`-Ebenen\n",
    "und zum Schluss noch ein Fully-connected Layer, welches wir durch `tf.keras.layers.Flatten`\n",
    "und `tf.keras.layers.Dense` bekommen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "pFrUQxJmzKhF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "23cc6dd9-0a72-4ef4-a465-077ad2813ae2"
   },
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(image_size, image_size, 3)),\n",
    "    MaxPool2D(pool_size=(4,4), strides=4),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation='softmax'),\n",
    "])\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "lUeJcSpHzKhH"
   },
   "source": [
    "Für unsere Loss-Funktion verwenden wir Categorical Crossentropy\n",
    "und für den Optimierer verwenden wir `tf.keras.optimizers.Adam`,\n",
    "da dieser bessere Ergebnisse als Stochastic Gradient Descent liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    },
    "id": "GJRFwqkSzKhI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d39b69f-39c7-405b-b8fb-d17895798077"
   },
   "source": [
    "Mit `fit()` trainieren wir das neuronale Netz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=2, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "KVZ5XHpZzKhJ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "outputId": "46c7a8a1-62d4-4b8b-9511-9da7b1da1210"
   },
   "source": [
    "Betrachten wir nun das Test-Set.\n",
    "Da das Test-Set nicht gemischt wurde,\n",
    "sind die ersten Bilder alles korrekt getragene Masken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "plot_images(test_imgs)\n",
    "print(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "SE2m5z13zKhL"
   },
   "source": [
    "Nun sagen wir das Test-Set mithilfe unseres trainierten Netzes mit `predict()` vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "l-9T7RGxzKhL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3eee0b24-cd28-490f-bc7b-01887bceeeb4"
   },
   "source": [
    "import numpy as np\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "print(\"Predictions:\\n\", preds)\n",
    "print(\"Actual:\\n\", test_batches.classes)\n",
    "print(\"Accuracy:\", sum(preds == test_batches.classes)/preds.shape[0])"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 0 0 2 2 2 2 2 2 2\n",
      " 2 0 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 1 2 2 2 2 2 2 0 2 2 2 2 0 1 2 2\n",
      " 2 2 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 1 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Actual:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Accuracy: 0.93\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}