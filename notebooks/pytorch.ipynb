{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Beispiel sehen wir uns MNIST an.\n",
    "Hierbei handelt es sich um eine Datenbank aus\n",
    "70000 handgeschriebenen Ziffern, davon 60000 im Trainings-\n",
    "und 10000 im Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(\"data\", train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = datasets.MNIST(\"data\", train=False, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Diesen Datensatz packen wir nun in einen passenden `DataLoader`.\n",
    "Mit diesem können wir gut über Datensätze iterieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das erste Element des DataLoaders sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 5, 1, 1, 9, 4, 8, 9, 1, 4, 7, 4, 2, 2, 7, 9, 8, 8, 5, 2, 1, 9, 0, 2,\n",
      "        7, 3, 5, 5, 9, 9, 0, 9, 7, 9, 1, 3, 1, 8, 3, 6, 6, 3, 3, 9, 9, 2, 9, 4,\n",
      "        0, 4, 6, 8, 3, 5, 9, 6, 3, 6, 4, 4, 0, 7, 4, 6, 1, 9, 9, 9, 8, 0, 7, 5,\n",
      "        7, 6, 0, 4, 2, 9, 7, 5, 3, 4, 5, 6, 6, 2, 5, 8, 8, 5, 0, 8, 0, 9, 9, 8,\n",
      "        2, 2, 6, 1])]\n"
     ]
    }
   ],
   "source": [
    "fst_data = next(iter(train_loader))\n",
    "print(fst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Betrachten beispielhaft wir die erste Ziffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Value: 8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fst_image = fst_data[0][0]\n",
    "fst_digit = fst_data[1][0].item()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(fst_image.view(fst_image.shape[1], fst_image.shape[2]))\n",
    "plt.title(f\"Value: {fst_digit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistische Regression\n",
    "Nun erstellen wir die Architektur der logistischen Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<img src=\"assets/fcnn-28x28-64-10.svg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetzt initialisieren wir die Loss class und den Optimizer (Stochastic Gradient Descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images_test, labels_test in loader:\n",
    "        images_test = Variable(images_test.view(-1, 28*28))\n",
    "        outputs = model(images_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels_test.size(0)\n",
    "        correct += (predicted == labels_test).sum()\n",
    "    acc = correct.item() / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Loss: 0.82982. Test Accuracy: 0.826.\n",
      "Epoch 2/3\n",
      "Loss: 0.51943. Test Accuracy: 0.873.\n",
      "Epoch 3/3\n",
      "Loss: 0.36164. Test Accuracy: 0.891.\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(3):\n",
    "    print(f\"Epoch {epoch+1}/3\")\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # we use torch.autograd.Variable for backpropagation\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_accuracy = calculate_accuracy(test_loader)\n",
    "    print(f\"Loss: {loss.item():.5f}. Test Accuracy: {test_accuracy:.3f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
