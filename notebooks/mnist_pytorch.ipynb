{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Beispiel sehen wir uns MNIST an.\n",
    "Hierbei handelt es sich um eine Datenbank aus\n",
    "70000 handgeschriebenen Ziffern, davon 60000 im Trainings-\n",
    "und 10000 im Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(\"data\", train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = datasets.MNIST(\"data\", train=False, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Diesen Datensatz packen wir nun in einen passenden `DataLoader`.\n",
    "Mit diesem können wir gut über Datensätze iterieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das erste Element des DataLoaders sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([6, 2, 2, 7, 4, 9, 2, 9, 6, 0, 6, 6, 9, 8, 5, 1, 4, 5, 6, 3, 6, 3, 7, 4,\n",
      "        1, 7, 4, 8, 1, 0, 7, 4, 4, 5, 2, 9, 6, 1, 0, 3, 4, 2, 7, 9, 0, 8, 0, 1,\n",
      "        4, 8])]\n"
     ]
    }
   ],
   "source": [
    "fst_data = next(iter(train_loader))\n",
    "print(fst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Betrachten beispielhaft wir die erste Ziffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Value: 6')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fst_image = fst_data[0][0]\n",
    "fst_digit = fst_data[1][0].item()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(fst_image.view(fst_image.shape[1], fst_image.shape[2]))\n",
    "plt.title(f\"Value: {fst_digit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multilayer Perceptron\n",
    "Nun erstellen wir die Architektur des neuronalen Netzes. Wir verwenden hier ein Fully Connected Neural Network mit einem Hidden Layer mit 64 Knoten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<img src=\"assets/fcnn-28x28-64-10.svg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLayerPerceptron()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetzt initialisieren wir die Loss class und den Optimizer (Stochastic Gradient Descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images_test, labels_test in loader:\n",
    "        images_test = Variable(images_test.view(-1, 28*28))\n",
    "        outputs = model(images_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels_test.size(0)\n",
    "        correct += (predicted == labels_test).sum()\n",
    "    acc = correct.item() / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Loss: 0.41999. Test Accuracy: 0.876.\n",
      "Epoch 2/3\n",
      "Loss: 0.62606. Test Accuracy: 0.900.\n",
      "Epoch 3/3\n",
      "Loss: 0.33089. Test Accuracy: 0.906.\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # we use torch.autograd.Variable for backpropagation\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_accuracy = calculate_accuracy(test_loader)\n",
    "    print(f\"Loss: {loss.item():.5f}. Test Accuracy: {test_accuracy:.3f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
